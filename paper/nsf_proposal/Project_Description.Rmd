---
title: "Public Opinion Regarding Climate Change"
subtitle: | 
  | Measuring Public Concern and Polarization
  | Across Countries and Over Time
  |
  | Project Description
date: "\\vspace{-7em}"
csl: american-political-science-association.csl
output: 
  pdf_document:
    includes:
    extra_dependencies: ["float"]
    template: null
    keep_tex: no
    number_sections: true
documentclass: nsf2
bibliography: references.bib
biblio-style: apalike
header-includes:
      - \usepackage{times}
      - \usepackage[fontsize=12pt]{scrextend}
      - \usepackage{wrapfig}
      - \date{\vspace{-10em}} 
      - \renewcommand{\topfraction}{.85} # Adjust LaTeX placement rules per 
      - \renewcommand{\bottomfraction}{.7} # https://bookdown.org/yihui/rmarkdown-cookbook/figure-placement.html
      - \renewcommand{\textfraction}{.15}
      - \renewcommand{\floatpagefraction}{.66}
      - \setcounter{topnumber}{3}
      - \setcounter{bottomnumber}{3}
      - \setcounter{totalnumber}{4}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  dpi = 600,
  fig.width = 7,
  fig.height = 4,
  plot = function(x, options)  {
    hook_plot_tex(x, options)
  }
)

if (!require(pacman))
    renv::install("pacman")
library(pacman)
p_install_gh(c("fsolt/DCPOtools"))
library(tidyverse)
library(here)
library(RColorBrewer)
library(patchwork)
library(DCPOtools)
```

```{r cc_summary_stats}

surveys <-  read_csv(here::here("data-raw/climate_index_cli.csv"),
                       col_types = "cccc")[c(1:26,29:141,145:455,458:480),]

dcpo_input_raw_cc <- read_csv(here::here("data-raw/dcpo_input_raw_cc.csv")) 

with_min_coverage <- function(x, min_cov) {
  if (!is.na(min_cov)) {
    country <- year <- years <- spanned <- coverage <- NULL
    x <- x %>%
      group_by(country) %>%
      mutate(years = length(unique(year)),
             spanned = length(min(year):max(year)),
             coverage = years/spanned) %>%
      filter(coverage >= min_cov) %>%
      select(-years, -spanned, -coverage) %>%
      ungroup()
  }
  return(x)
}
with_max_gap <- function(x, max_gap, edges = TRUE) {
    if (!is.na(max_gap)) {
        country <- yr_obs <- NULL
        c_yrs <- x %>% 
            group_by(country, year) %>% 
            summarize(year = first(year)) %>% 
            mutate(lead_span = ifelse(!is.na(lead(year)),
                                      lead(year) - year - 1,
                                      50),
                   lag_span = ifelse(!is.na(lag(year)),
                                     year - lag(year) - 1,
                                     50),
                   min_span = pmin(lead_span, lag_span),
                   max_span = pmax(lead_span, lag_span),
                   drop = min_span > max_gap & max_span == 50)
        
        x <- x %>% 
          left_join(c_yrs,
                    by = c("country", "year")) %>% 
          filter(!drop) %>% 
          select(-contains("span")) %>% 
          select(-drop)
    }
    return(x)
}

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
  dcpo_input_raw_df %>% 
    with_min_yrs(3) %>% 
    with_min_cy(5) %>% 
    with_min_yrs(3) %>% # double-check after dropping <5 cy
    filter(year >= 1972 & n > 0) %>% 
    group_by(country) %>% 
    mutate(cc_rank = n()) %>% 
    ungroup() %>% 
    arrange(-cc_rank)
}


dcpo_input_raw_cc <- process_dcpo_input_raw(dcpo_input_raw_cc)


n_surveys <- surveys %>%
  distinct(survey) %>% 
  nrow()  

n_items <- dcpo_input_raw_cc %>%
  distinct(item) %>% 
  nrow() 

n_countries <- dcpo_input_raw_cc %>%
  distinct(country) %>% 
  nrow()  

n_cy <- dcpo_input_raw_cc %>%
  distinct(country, year) %>% 
  nrow() %>% 
  scales::comma() 

n_years <- as.integer(summary(dcpo_input_raw_cc$year)[6]-summary(dcpo_input_raw_cc$year)[1]) 

spanned_cy <- dcpo_input_raw_cc %>% 
  group_by(country) %>% 
  summarize(years = max(year) - min(year) + 1) %>% 
  summarize(n = sum(years)) %>% 
  pull(n) %>% 
  scales::comma() 

total_cy <- {n_countries * n_years} %>% 
  scales::comma()  

year_range <- paste("from",
                    summary(dcpo_input_raw_cc$year)[1], 
                    "to",
                    summary(dcpo_input_raw_cc$year)[6]) 
n_cyi <- dcpo_input_raw_cc %>% 
  distinct(country, year, item) %>% 
  nrow() %>% 
  scales::comma() 
back_to_numeric <- function(string_number) {
  string_number %>% 
    str_replace(",", "") %>% 
    as.numeric()
}
covered_share_of_spanned <- {back_to_numeric(n_cy)/back_to_numeric(spanned_cy) * 100}

top_country_cyi <- dcpo_input_raw_cc %>% 
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(-n) %>% 
  slice_head() %>%
 pull(country) 

top_country_cyi_obs <- dcpo_input_raw_cc %>%
  filter(country == top_country_cyi) %>%
  distinct(country, year, item) %>%
  nrow()  

others_cc <- dcpo_input_raw_cc %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(desc(n)) %>%
  slice(2:5) %>%
  pull(country) %>% 
  paste(collapse = ", ") %>% 
  str_replace(", (\\w+)$", ", and \\1") # "Spain, France, Italy, and Netherlands""


y_cc_peak_year <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(year) #2010

y_cc_peak_nn <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(nn) #74 countries

data_cc_poorest <- dcpo_input_raw_cc %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(n) %>%
  filter(n < 10) %>%
  pull(country) %>% 
  paste(collapse = ", ") %>% 
  str_replace(", (\\w+)$", ", and \\1")  #Palestinian Territories, Tunisia, Uganda, Armenia, German Democratic Republic, Ghana, Pakistan, Taiwan, and Tanzania

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

n_cc_data_poorest <- {data_cc_poorest %>%
    str_split(",") %>% 
    first()} %>% 
  length() %>% 
  wordify_numeral()
```


Effectively addressing climate change necessitates understanding the interplay between policy, politics, and public opinion.
Understanding how public opinion on climate change affects policy, especially across partisan lines, urban-rural divides, and gender differences, is crucial, as polarization challenges the implementation and sustainability of climate reforms.
However, existing theories often prioritize collective action problems [@ostrom1990governing;@barrett2003environment;@nordhaus2015climate;@keohane2016cooperation] and distributive politics [@colgan2021asset; @aklin2020prisoners], overlooking the critical role of public attitudes, despite their influence on government actions in democracies [@dahl1971polyarchy; @burstein2003impact] and in authoritarian countries [@alkon2018pollution].
We analyzed 70 highly-cited articles on public opinion toward climate change, identified from the top 50 results on Web of Science and on Google Scholar (duplicates removed), spanning 1998 to 2022.
Many of these studies relied on case-study or small-n designs, with nearly half examining four or fewer countries and years, and over a third focusing on a single year in a single country.
This highlights the significant absence of comprehensive, longitudinal, and cross-national studies in the field, making it imperative to fill this critical research gap.

The reason for this oversight is the lack of systematic cross-country public opinion data on climate change.
Comparative public opinion data are sparse and fragmented, with many countries and years lacking data, and existing data often being incomparable due to differences in items and interpretations.
These challenges are particularly severe for climate change opinion.
Unlike established concepts such as democratic support, trust, and gender egalitarianism, climate-related questions have only been surveyed sporadically since the 1990s, mainly in developed countries.
Actually, even for OECD countries, due to the absence of comparative data, @schaffer2022policymakers had to use media coverage of climate issues as a proxy for public concerns.
Our preliminary data collection from `r n_items` from `r n_surveys` different survey datasets, `r year_range`, highlights this sparsity, with only `r n_cyi` country-year-item available observations representing `r round({as.numeric(n_cy)/as.numeric(total_cy %>% str_remove(","))} * 100)`% of the total possible country-year data.

In addition to the average level of public climate concern, how such concerns are distributed within a society, especially along with existing salient social cleavages -- partisan lines, urban-rural divide, and gender differences, to name but a few -- is equally if not more important for climate policies.
Polarization in climate concerns captures the intuition that significant differences in views and preferences towards climate issues exist and likely increase between different groups of people in a society.
It is an important concept with profound policy implications.
Addressing the climate challenge requires a transformation of our societies and this scale of change depend upon far-reaching reforms from governments that many believe are only possible when there is a widespread social and political support for such a transition (Bechtel and Scheve 2013).
Increasing political polarization of climate policy-relevant attitudes would inhibit such climate reforms.
Indeed, popular disagreement on issues surrounding climate policies provides fertile grounds for political mobilization that often blocks necessary reforms.
Therefore, many believe that political polarization of public attitudes relevant to climate change presents a challenge for not only the implementation but also the durability of climate reforms (McCright et al. 2011).
However, due to the scattered and sparse data, we do not have measures of polarization on climate change public opinion beyond a few advanced ecoonomies.

To address these challenges, we will rely on the Dynamic Comparative Public Opinion model [DCPO, @solt2020modeling] for latent variable estimation on climate change concern and polarization.
The DCPO model has been widely used in cross-national opinion estimation [@woo2023public;@humacrointerest;@woo2023measuring] among other latent variable models [e.g.,@claassen2019estimating; @caughey2019policy; @mcgann2019parallel;@kolczynska2024modeling].
We plan to expand the survey source data both temporally and geographically by including more country-specific surveys.
We will also improve the latent-variable estimation model by incorporating new techniques to ensure DCPO's estimates are comparable.
This includes setting stronger priors for change over time and in data-poor countries, and nesting similar items in hierarchical models to address item-comparability issues.
Additionally, we will develop and test various methods for generating polarization estimates.

Our project aims to build crucial research infrastructure for cross-national work on climate change, polarization, and broader public opinion.
We will disseminate the resulting estimates to researchers, educators, students, and policymakers worldwide through conference presentations, a symposium, scholarly publications, and a web interface.
This work will enhance our understanding of the relationship between public opinion and climate policies, ultimately contributing to more informed and effective climate actions.

# Background
There is a very large existing literature that explains public opinion on climate change (e.g., citizen knowledge, attention, concern for climate change as well as policy preferences) in especially developed economies.
For instance, many have shown that extreme weather events (e.g., droughts, wildfires, and hurricanes) triggered by climate change increase public climate change concerns and preferences for mitigation policies.
This scholarly enthusiasm to explain climate public opinion is probably underpinned by an underlying assumption that one needs public support to produce climate policies to combat climate change; in other words, public opinion matters in the realm of climate policies.
But does it? More specifically, would public opinion on climate change affect national climate change policy outputs?
Surprisingly, the literature is silent when it comes to this obvious and yet extremely important question.
The reason for this is simple and yet it presents a great challenge for the research community: there is no systematic data on cross-country public opinion regarding climate change. 

With the looming threat of climate change, it is vital for us to understand climate policies and politics.
Existing theories on the subject largely focus on collective action and distributive politics, ignoring the potential impact of public sentiment.
Collective action theory treats carbon mitigation as a global public good, with countries free-riding on one another the core challenge [@ostrom1990governing;@barrett2003environment;@nordhaus2015climate;@keohane2016cooperation].
However, it fails to explain why some countries are more proactive/less free-riding in mitigation than others.
Distributive politics, on the other hand, views climate policy as a battleground for interest groups, some of which  would lose while others might gain from climate mitigation [@colgan2021asset; @aklin2020prisoners].
Owners of so called ''climate-forcing'' assets (those generating large amounts of carbon emissions) stand to lose with stringent mitigation policies and have been a large barrier to effective climate policy.
One key question that remains to be answered is whether pro-mitigation public preferences can outweigh these anti-mitigation forces.
<!--The key question is: (how) does public opinion influence climate policy?-->

Traditional wisdom suggests that public opinion influences public policy through government responsiveness [@dahl1971polyarchy], a dynamic observed even in authoritarian countries [@alkon2018pollution; @miller2015elections; @meng2017conditional].
In @burstein2003impact's influential review on public opinion and policy, it was found that while public opinion often strongly influences policy, most studies focus on the US and a few West European countries, with minimal attention to developing countries.
According to the Web of Science, since 1990, there have been 1,829 articles on environment/climate change and public opinion, with 306 focused on the United States, 128 on China, 114 on the EU, 38 on Africa, and 15 on Latin America.
Narrowing the scope to cross-national research reduces the count to 28.
Among these, most studies have examined the determinants of environment/climate attitude and the determinants climate policies independently [@stenner2015current;@papiez2018determinants;@fankhauser2014domestic;@hao2021really]; few consider the role of public opinion in affecting environmental and climate policy outputs: here only proxy measures of climate public opinion (e.g., using environmental rather than climate attitudes or media coverage of climate issues) are used [@anderson2017public; @bakaki2020triangular; @schaffer2022policymakers]. 

Again, cross-national analyses overlook the role of public opinion due to data limitations.
Even for broader attitudes towards environmental issues, comprehensive multi-decade, cross-national surveys are lacking [@von2022democracy]. @anderson2017public found a positive relationship between public environmental attitudes (using Eurobarometer data) and renewable energy policy outputs in Europe from 1974 to 2015.
Similarly, @bakaki2020triangular identified a triangular relationship between citizens' environmental concerns, media attention, and renewable policy output in six European democracies from 1983 to 2012.
The limited spatial coverage is primarily due to the lack of data.
The situation is even more severe for climate change attitudes.
Due to the absence of comparative climate opinion data, @schaffer2022policymakers used media coverage of climate issues as a proxy for public concerns in studying climate change mitigation in six OECD countries over a period of 1995-2010, even though this measure has low validity given its low correlation (r = 0.27) with climate public opinion data [@oehl2017measure] and the authors acknowledge that "public opinion surveys arguably provide the most direct measure of public demand." [see, p.~137, @schaffer2022policymakers].

In addition to the average level of public climate concern, how such concerns are distributed within a society, especially along with existing salient social cleavages---partisan lines, urban-rural divide, and gender differences, to name but a few---is equally if not more important for climate policies.
Polarization in climate concerns captures the intuition that significant differences in views and preferences towards climate issues exist and likely increase between different groups of people in a society.
It is an important concept with profound policy implications.
Addressing the climate challenge requires a transformation of our societies and this scale of change depend upon far-reaching reforms from governments that many believe are only possible when there is a widespread social and political support for such a transition.
Increasing political polarization of climate policy-relevant attitudes would inhibit such climate reforms.
It signifies popular disagreement on issues surrounding climate policies and provide fertile grounds for political mobilization that often blocks necessary reforms.
Therefore, many believe that political polarization of public attitudes relevant to climate change presents a challenge for not only the implementation but also the durability of climate reforms.

Besides the overall levels of public concern over climate change and support for climate policies, how polarized such concern and support are matters greatly for policy adoption and implementation. Combatting climate change often demands ambititious and comprehensive changes in the way we live our lives (e.g., driving EVs), which in turn often requires (costly) government policies to support such changes (e.g., subsidizing EV production and purchases and the construction of more charging stations). It is simply more difficult for a  polarized society to reach concensus and push through such necessary reforms.   

Even though we have seen no systematic, large-N analysis studying the effect of polarization on climate policies in a cross-country context, there are many studies connecting polarization to important political and policy outputs and outcomes in other issues areas.
For instance, some have argued that polarization affects government accountability (Jones 2015; Bornschier 2019); others have shown that polarization can make party brands more visible, therefore helping voters with clearer choices during elections (Lupu 2015 and Singer 2016).
At the same time, polarization might also result in instability in legislative process and democratic backsliding (McCoy and Somer 2019; Stavrakakis 2018).
Elsewhere, Iversen and Soskice (2015) discover a negative correlation between mass polarization and income inequality; they argue that in the context of advanced economies such a correlation is a function of political information available to voters.
Using data from the 1999 European Election Study and an expert survey on party positions, Lachat (2008) shows that the role of citizens' left–right orientations in affecting voting behaviors increases with party system polarization.
Lindqvist and Östling (2010) find that political polarization is strongly associated with smaller government in democracies, but there is no such relationship in undemocratic countries.\footnote{Though they acknowledge that multiple explanations exist for a connection between polarization and government spending, and they can point to different directions (e.g., polarization could lead to conflicts of interest among the poor that affect their ability to form coalitions for increased redistribution).}

Also, the study of polarization is not limited to the case of the United States – even though US saw most of the studies on the subject largely because of its rich data.
Other regions of the world, even countries outside the advanced economies, have seen an increasing number of studies on polarization. 
For instance, Church and Vatter (2016) highlight the extreme polarization of public opinion as the first of the five most important changes reshaping Swiss politics today.
Still in Western European context, Moral (2017) shows that high party polarization increases voter turnout for both politically sophisticated and unsophisticated citizens, using individual and party system-level data from 17 European multiparty democracies.
Evans and Need (2002) test the effectiveness of competing explanations of ethnic polarization in attitudes towards minority rights in 13 East European societies; they find that cultural differences explain polarization not only at the individual, but also regional and cross-national levels.
In an Asian context, Slater and Arugay (2018) present a comparative analysis of polarizing crises in five Asian democracies; they show what explains crisis severity and resolution is not traditional fault lines between left and right, rich and poor, and secular and religious, but how the leading elite opponents of polarizing figures managed their removal from office. 
Singer (2016) shows that in developing democracies such as those in Latin America, political polarization increases representation because it helps parties better differentiate themselves from each other and make it easier for voters to see the connection between their personal ideologies and the electoral offerings. 

Public opinion on climate change has become increasingly complex during times of polarization.
Yet, when we zoom in on polarization in climate change, we find that past studies often focus on the case of the US, they are descriptive in nature, and no study has tested the effect of polarization on climate policies in a cross-country setting.
Indeed, in the U.S., climate change is a deeply divisive and politicized issue, with political ideology significantly influencing attitudes towards climate and environmental policies [@mccright2011politicization; @czarnek2021right;@jasny2015empirical].
For instance, liberals generally show greater support for climate change policies than conservatives [@boudet2020event; @hazlett2020wildfire; @mccright2016ideology;@egan2017climate; @merkley2018party].
This polarized view on climate change can be traced all the way back to the early 1990s.
Since then, Americans’ climate attitudes have become more and more strongly associated with their partisan and ideological affiliations.
Many attribute this trend of polarization to the influence of conservative political elites’ climate denial campaigns upon Republican voters (Tesler 2018). 
Whether similar levels of climate polarization have occurred in other countries, however, remains an open question.
It seems that climate attitude polarization (based on political party affiliations for example) does exist in other English-speaking countries including Australia, Canada, and the UK (Lachapelle et al. 2012; Tranter 2013; Kenny 2022) as well as in some western European countries such as Switzerland (Lüth and Schaffer 2022).
Yet, there is no evidence that such polarization exists in Eastern European countries (Fisher et al. 2022) and as far as we know, no study has looked at polarization in climate change public opinion beyond North American and European countries.   

There are at least three major obstacles that prevent the study of climate public opinion polarization in a cross-country setting.
First, other than partisan polarization, factors such as gender, race, education, income, and socioeconomic status also influence public climate attitudes, as shown in various cross-national studies [@lewis2019cross, @pearson2017race, @hornsey2016meta, @lee2015predictors].
For instance, women in wealthier countries in the Americas and Europe are more likely to be concerned about climate change than men, possibly because men perceive higher costs in climate mitigation policies since they benefit more from the current hierarchical political and social system [@bush2023facing].
Identifying (most) relevant fault lines that divide public opinion in cross-country setting is challenging because one needs country-specific knowledge regarding key social cleavages.
Second, one needs survey data with individual-level variables that measure these cleavages, and these surveys also need to include questions on climate change concerns.
Once we move out of advanced countries, such surveys become less common. Finally, there are various ways to measure polarization and there is no concensus regarding which approach is better in general and in our context of climate change attitude polarization.


It is well documented that comparative public opinion studies have been hampered by the lack of comprehensive data, not to mention public polarization data.
The scarcity of comparative data at the aggregate level is due to data sparseness and fragmentation, with many countries and years lacking data, and existing data often being incomparable due to differences in items and interpretations.
However, an emerging group of scholars has been dedicated to developing models to measure comparative public opinion across countries over time [@claassen2019estimating; @caughey2019policy; @mcgann2019parallel; @kolczynska2024modeling; @solt2020modeling].
Among these, the Dynamic Comparative Public Opinion model [DCPO, @solt2020modeling] has been widely used to measure comparative public opinion and has successfully created comparative data for views on gender equality in politics and the workplace [@woo2023public], political interest [@humacrointerest], and attitudes toward gay rights [@woo2023measuring].

```{r pocc-plot, fig.cap="Countries and Mean Years Observed in Prominent Research\\label{pocc_plot}", fig.height=4.5, fig.width=7.5, fig.pos='h', cache=FALSE}

cited <- tribble(~citation, ~text_x, ~text_y,
                 "Clements and Field 2014", 8.8, 42,
                 "Yang 1997", 4.7, 26,
                 "Hildebrandt et al. 2019", 72, 0,
                 "Adamczyk and Pitt 2009", 40, -.5,
                 "Reynolds 2013", 80.7, 2.9,
                 "Redman 2018", 65.5, 2.9,
                 "Hooghe and Meeusen 2013", 37.6, 4.24)

pocc <- read_csv(here::here("data-raw", "savedrecs.csv"),
                 show_col_types = FALSE) %>% 
  bind_rows(read_csv(here("data-raw", "savedrecs_gs.csv"),
                     show_col_types = FALSE) %>% 
              select(-`End Page`)) %>% 
  janitor::clean_names() %>% 
  mutate(year = publication_year,
         hits = times_cited_all_databases,
         last_names = str_remove_all(authors, ", [A-Z]{1,3}") %>% 
           str_to_title() %>% 
           str_replace_all(";", ",") %>% 
           {ifelse(str_count(., ",") > 1,
                   str_replace(., ",.*", " et al."),
                   .)} %>% 
           str_replace(", ([A-Z][a-z]+)$", ", and \\1") %>% 
           str_replace("^([A-Z][a-z]+(?:-[A-Z][a-z]+)?), and ([A-Z][a-z]+)$", "\\1 and \\2"),
         citation = paste(last_names, year),
         cy = k*t) %>% 
  group_by(k, t) %>% 
  mutate(to_jitter = n() > 1) %>% 
  ungroup() %>% 
  filter(!is.na(k) & k > 0)#%>% 
    # left_join(cited, by = "citation")

my_palette <- colorRampPalette(brewer.pal(11, "Spectral"))
color_scale <- scale_color_gradientn(colors = my_palette(max(pocc$year) -
                                                             min(pocc$year) + 1),
                                     limits = c(min(pocc$year),
                                                max(pocc$year)),
                                     name="Publication\nYear")
fill_scale <- scale_fill_gradientn(colours = my_palette(max(pocc$year) -
                                                            min(pocc$year) + 1),
                                   limits = c(min(pocc$year),
                                              max(pocc$year)),
                                   name="Publication\nYear")

set.seed(324)
pocc_plot <- ggplot(pocc, aes(x = k,
                            y = t,
                            color = year,
                            fill = year)) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(!to_jitter),
               alpha = .75) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(to_jitter),
               alpha = .75,
               position = position_jitter(width = .25, height = .25)) +
    # geom_text(aes(label = citation,
    #               x = text_x,
    #               y = text_y,
    #               size = 35),
    #           data = pocc %>% filter(!is.na(text_x)),
    #           color = "grey20") +
    color_scale +
    fill_scale +
    theme_bw() +
    theme(legend.justification = c(.99,.99), 
          legend.position = c(.98,.98),
          legend.box.background = element_rect(color = "grey",
                                               fill="white"),
          legend.box="horizontal") +
    scale_size(name = "Citations") +
  coord_cartesian(xlim = c(0, 125), ylim = c(0, 20)) +
    labs(x = "Countries Observed",
         y = "Mean Years Observed Per Country Observed",
         title = "Prominent Articles on\nPublic Opinion on Climate Change") +
  annotate(geom = "rect", 
           xmin = 0, xmax = 5, 
           ymin = 0, ymax = 5,
           color = "black", 
           fill = NA,
           linewidth = .25 ) +
  geom_segment(aes(x = 0, y = 5, xend = 19.4, yend = 19.4),
               linetype = "dashed",
               color = "gray",
               linewidth = .25) +
  geom_segment(aes(x = 5, y = 0, xend = 70, yend = 4.5),
               linetype = "dashed",
               color = "gray",
               linewidth = .25)

set.seed(324)
zoom_plot <- ggplot(pocc, aes(x = k,
                            y = t,
                            color = year,
                            fill = year)) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(!to_jitter),
               alpha = .75) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(to_jitter),
               alpha = .75,
               position = position_jitter(width = .25, height = .25)) +
    # geom_text(aes(label = citation,
    #               x = text_x,
    #               y = text_y,
    #               size = 35),
    #           data = pocc %>% filter(!is.na(text_x)),
    #           color = "grey20") +
    color_scale +
    fill_scale +
    theme_bw() +
    theme(legend.position = "none",
          plot.background = element_rect(colour = "black",
                                         fill = "white",
                                         linewidth =.5)) +
    coord_cartesian(xlim = c(0, 5), ylim = c(0, 5)) +
    labs(x = NULL,
         y = NULL)

pocc_plot + 
    inset_element(zoom_plot, 15/80, 10/40, 44/80, 37/40) +
    plot_annotation(caption = str_wrap("Note: Citation counts as reported by the Web of Science on June 15, 2024.", 
                                       width = 114))
```


Regarding climate change public opinion, we first explored the country-year coverage of climate-change questions in existing surveys and the literature.
Figure\nobreakspace{}\ref{pocc_plot} shows how the available data have influenced scholarship on the topic.
Using the Web of Science and Google Scholar, we assembled a sample of prominent published articles on public opinion toward climate change.^[
Web of Science topic searches return articles in which the search terms appear in the title or abstract.
We executed the following search: `TS=("public opinion" AND ("climate change" OR "global warming" OR "greenhouse effect"))`.
The fifty most-cited empirical research articles returned were retained.
Google Scholar, [according to its about page](https://scholar.google.com/intl/en/scholar/about.html), "aims to rank documents the way researchers do, weighing the full text of each document, where it was published, who it was written by, as well as how often and how recently it has been cited in other scholarly literature."
We searched `"public opinion" "climate change"` and identified the first fifty articles returned.
Then we added the Web of Science records for the Google Scholar results (to ensure consistency of citation counts) to our original Web of Science sample and dropped all duplicates, yielding a total of `r nrow(pocc)` different articles.]
These articles had publication dates as early as `r summary(pocc$year)[[1]]` and as late as `r summary(pocc$year)[[6]]` (median: `r summary(pocc$year)[[3]]`) and were cited in the Web of Science from `r summary(pocc$hits)[[1]]` to `r summary(pocc$hits)[[6]]` times (median: `r summary(pocc$hits)[[3]]`).
We then examined these articles to find the number of countries and years investigated in each.
As the zoomed portion of the plot pocc-plot emphasizes, many of these articles might be described as using case-study or small-_n_ research designs.
Just over a third consider only a single year in a single country; together with works that study four and fewer countries and years (inset) they comprise nearly half of this sample.

In addition, climate change survey data presents distinctive challenges.
First, the data are particularly fragmented among many different survey questions due to the rapid changes in the salience of the climate change topic and specific subtopics, from climate knowledge to policy preference.
Second, an unusually large number of countries are data-poor.
<!-- plots of country-years per question across topics (climate change vs. PGE vs. macrointerest, for example).-->
Moreover, regarding climate-change opinion, researchers are particularly interested in _polarization_ in attitudes, but existing latent-variable solutions have paid little attention to this.

The lack of extensive cross-sectional time series data on public opinion and polarization regarding climate change significantly impedes research in the fields of opinion and climate policy.
Our project aims to expand both the geographic and temporal dimensions and contribute to the literature on public opinion, polarization, and policy outcomes related to climate change policies.


# The Proposed Research

The proposed research comprises four principal activities: (1) expanding the survey source data, (2) generating estimates for public opinion on climate change, (3) developing and testing a range of methods for generating polarization estimates, and (4) disseminating the resulting estimates to researchers, educators, students, and policymakers worldwide through conference presentations, scholarly publications, open-source software, and a web interface.

We will rely on the Dynamic Comparative Public Opinion model (DCPO) [@solt2020modeling] to measure public opinion since it has been widely used in measuring comparative public opinion and successfully generated comparative datasets in gender egalitarianism [@woo2023public], macrointerest [@humacrointerest], and tolerance of homosexuality [@woo2023measuring].

The DCPO model is a population-level two-parameter ordinal logistic item response theory (IRT) model.
It interprets an individual's response to a certain question as a function of the mean latent public attitude of a population at a country-year level, the difficulty of giving a certain answer to the question, and the degree to which the question measures the latent attitude.
By incorporating country-specific characteristics that capture systematic differences in responses due to cultural factors or distinct interpretations, DCPO ensures comparability of measured latent attitudes between countries.
Furthermore, through local random walk, DCPO smooths the missing measures based on available data from previous years.

*Expanding the survey source data.* 

To measure public opinion toward climate change, by using DCPOtools in our initial efforts, we have identified `r n_items` such survey items that were asked in at least five country-years in countries surveyed more than three times from `r n_surveys` different survey datasets.
These items have been asked in `r n_countries` different countries at least three times over the past `r n_years` years, `r year_range`.

The current source data covers `r n_cy` country-years and includes a total of `r n_cyi` country-year-item observations, which represents `r round({as.numeric(n_cy)/as.numeric(total_cy %>% str_remove(","))} * 100)`% of a complete set of total country-year data.

The left panel of Figure \ref{item_country_plots} shows the years observed by country in current dataset.
We have more year data in European countries and the United States but fewer data in African and Asian continents. 
The upper right panel shows the top countries with the highest count of year-item observations.
The `r top_country_cyi` has `r top_country_cyi_obs` observations, followed by `r others_cc`.
The bottom right panel counts the countries observed in each year.
<!-- Country coverage reached its peak in `y_peak_year`, when respondents in `y_peak_nn` countries were asked items about climate change, but few relevant survey items were asked before 2007. -->

The number of items observed in the source data for each country-year is plotted in Figure\ref{obs_by_cy} below.
It demonstrates the potential for building a comprehensive cross-national time-series dataset on climate opinion while also highlighting the challenges in measuring comparative public climate data, including the variation in data availability geographically and temporally. 
Our primary focus has been on well-known and publicly-accessible cross-national surveys, including the World Values Survey, Eurobarometer, European Social Survey, International Social Survey Programme, and Regional Barometer surveys, supplemented by a few country-specific surveys.

```{r itemcountry, fig.cap="Countries and Years with the Most Observations in the Source Data \\label{item_country_plots}", fig.height=3.5, fig.width=6, fig.pos='h', cache=FALSE}
countries_plot <- dcpo_input_raw_cc %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  distinct(country, year, item) %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95, size = 7),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Year-Items\nObserved") +
  ggtitle("Countries")


cby_plot <- dcpo_input_raw_cc %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Years\nObserved") +
  ggtitle("Countries")

ybc_plot <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>%
  ggplot(aes(year, nn)) +
  geom_bar(stat = "identity") +
   scale_x_continuous(
    minor_breaks = seq(1989, 2023, by = 1),
    breaks = seq(1992, 2023, by = 2), limits = c(1991, 2023))  +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95, size = 6),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  xlab("Year") +
  ylab("Countries\nObserved") +
  ggtitle("Year")

world_map <- map_data("world") %>% 
  filter(!long > 180)

cby_map <- world_map %>% 
  distinct(region) %>% 
  mutate(country = countrycode::countrycode(region,
                                            "country.name",
                                            "country.name")) %>% 
  filter(!region=="Antarctica") %>% 
  left_join(dcpo_input_raw_cc %>% 
              count(country, year) %>% 
              count(country, name = "Years"),
            by = "country") %>% 
  mutate(Years = ifelse(is.na(Years), 0, Years)) %>% 
  ggplot(aes(fill = Years, map_id = region)) +
  geom_map(map = world_map,
           color = "white",
           size = 0.06) +
  coord_map(projection = "mollweide", 
            ylim=c(-80, 90),
            xlim=c(-170, 170)) +
  theme_void() +
  scale_fill_distiller(na.value = "gray90", 
                       palette = "Blues",
                       direction = 1) +
  ggtitle("Years Observed by Country") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position.inside = c(.05,.1),
        legend.justification = c(0,0), 
        legend.direction = "vertical") +
  scale_y_continuous(expand=c(0,0)) +
scale_x_continuous(expand=c(0,0))
cby_map + (countries_plot/ ybc_plot) + plot_layout(widths = c(3.8, 1.2))
```

```{r obs_by_cy, fig.height = 9, fig.width = 6.5, fig.cap = "Source Data Observations by Country and Year \\label{obs_by_cy}"}
dcpo_input_raw_cc %>% 
  mutate(country = str_replace(country, "’", "'")) %>% 
  distinct(country, year, item, cc_rank) %>% 
  group_by(country, year) %>% 
  summarize(n = n(),
            cc_rank = cc_rank) %>% 
  ungroup() %>% 
  distinct() %>% 
  ggplot(aes(x = year, 
             y = forcats::fct_reorder(country, cc_rank),
             fill = n)) + 
  geom_tile() +
  scale_fill_stepsn(colors = rev(hcl.colors(5, "inferno")),
                    n.breaks = 5,
                    show.limits = TRUE,
                    right = FALSE,
                    name = "Observations") +
  labs(x = NULL, y = NULL) +
  scale_x_continuous(breaks=seq(1992, 2022, 4),
                     sec.axis = dup_axis()) +
  scale_y_discrete(position = "right") +
  theme(legend.justification=c(0, 0), 
        legend.position=c(0.01, 0.01),
        axis.text.y  = element_text(size = 7)) 
```    


These established worldwide surveys have advantages in standardized questions and thorough documentation, but they also have limitations in geographic and temporal coverage.
For instance, the World Values Survey and Regional Barometer Survey are typically conducted every four years, while the International Social Survey Programme's topic modules are conducted approximately every five to ten years.
Relying solely on these publicly accessible cross-national surveys is insufficient.

There are also public but non-accessible survey projects.
For example, Gallup has included climate change questions in their surveys since 2005, providing a valuable dataset for climate change
However, this data is only available to subscribers, making it difficult to access without project funding. 

Expanding the dataset to include more country-specific surveys will enhance the geographical and temporal scope of the raw data.
However, this expansion will require a significant commitment of time and resources due to language barriers and other difficulties in accessing data.
For instance, the Finnish Social Science Data Archive has surveys with climate or energy-relevant questions dating back to 2000.
Most of these surveys are in Finnish, requiring research assistance to identify relevant questions and clean the raw data.
Similarly, other non-English surveys necessitate research assistance, further emphasizing the need for funding to hire skilled research assistants.

In addition to expanding survey datasets, we will expand survey items to include both climate-related items and environment-related items.
Both general questions about environmental concern and protection and specific questions about environmental policy preferences will be identified and incorporated into our source data.
Additionally, the severe sparsity of identical questions across different survey projects necessitates further development of the DCPO model to address these inconsistencies.
We will also identify demographic and political information of respondents in survey datasets, including but not limited to gender, religion, residence location, and ideology.
These demographics will allow us to estimate public opinion between subpopulations, which we will illustrate in the polarization estimates section. 

*Generating estimates for public opinion on climate change.*
To estimate public climate change attitudes across countries and over time, we employ the Dynamic Comparative Public Opinion (DCPO) model.
Other models usually require high quality data, either dense survey data or ancillary data on population characteristics [@mcgann2019parallel,@kolczynska2024modeling].
The latest development in this stream is @Berwick2024's dynamic multidimensional group-level IRT model.
By using an exploratory approach, their method can measure multidimensional opinions by poststratifying subpopulation opinion estimates. 
The exploratory method can help understand complex opinion structures when scholars care about dimensions.
For example, public support for democracy is a complex and multidimensional concept. 
Unidimensional measures of public support cannot capture public support in different dimensions, such as supporting contestation and participation; civil liberties; and institutional constraints on executive power [@hu2024multi]. 
In that case, their method can help scholars explore potential dimensions using a data-driven approach.
However, our aim is not to explore and measure multidimensional public opinion on climate change.
Even though there might be multiple dimensions, DCPO can detect items relevant to climate change that might measure different concepts and exclude these items from the latent variables.
This ensures that these items do not influence our opinion or polarization measures.

However, the practicality of poststratifying subpopulation estimates in scenarios involving numerous countries and extended time periods is questionable and may present challenges.
This approach is practical for single-country studies or when the sample of countries is small and regular census data are available.
However, collecting subgroup population proportions becomes an immense task when the sample size is large, especially when subgroups include factors like gender, religion, and ideology, as in our project.
Moreover, some countries in a worldwide study may lack available or accessible census data, further complicating the process, as we have encountered in our project.
Compared to these models, DCPO is specifically designed to address issues of incomparability and sparsity in comparative opinion data over time with fewer data requirements.

DCPO handles incomparability with two key parameters: _difficulty_ and _dispersion_. 
In our context of climate-related surveys, difficulty indicates the level of climate change attitude represented by a given response.
For instance, answering "very concerned" to the question "To what extent are you concerned about climate change?" shows more supportive attitude than answering "somewhat concerned," "little concerned," or "not at all."
Similarly, giving "very high priority" to the question "How high a priority do you think the government SHOULD place on addressing climate change?" indicates more support than merely expressing concern.

Dispersion measures the degree to which a question can capture the latent attitude towards climate change.
A smaller dispersion suggests that changes in question responses can better reflect changes in supportive attitudes.
For example, compared to the question about the degree of agreement with "Climate change is caused by human behavior," the response to "Would you be willing to give part of your income or pay more taxes if you were sure that the extra money was used to handle climate change?" can better map onto the change in climate attitude.
This is because people who acknowledge that climate change is caused by human behavior might not necessarily support any climate policies.
Their knowledge of climate change might not naturally translate into support for climate policies, due to other considerations such as confidence in the government's capacity to address climate issues or personal interests, like those of coal workers.

To address the sparsity of source data, which includes inconsistencies in the time series of each country due to unobserved country-years or limited observed items, DCPO uses local-level dynamic linear models.
These models estimate public opinion by taking the previous year's estimate and adding a random shock.
This approach smooths the estimates over time and allows for estimation even in years with little or no survey data, albeit at the expense of greater measurement uncertainty[^Scholars have developed and tested approaches to incorporate measurement uncertainty [@TaiEtAl2022a]].

To facilitate data collection, measurement, and broader open data science, DCPO has developed two open-source R packages: DCPO and DCPOtools.
DCPOtools, designed by @SoltEtAl2019, automates the process of collecting the necessary survey items from datasets and performs data wrangling computationally.
This increases the efficiency and transparency of data processing, avoids data entry errors, and facilitates reproducibility.
DCPO is the package written in Stan for running DCPO models and estimating latent public opinion from cross-national survey data collected through DCPOtools.
Together, these tools enable scholars to translate survey data into estimates of public opinion.


*Developing and testing a range of methods for generating polarization estimates.*
There are different ways to measure polarization.
Indeed, scholars have been using various polarization measures, likely contributing to the disagreement regarding the identification and consequences of polarization, especially in a comparative context [@mehlhaff2022group].
The most intuitive measures are distribution or distance measures; they capture the distance between the mean positions of groups: for example, the distance between the mean position of Republican voters and that of Democratic voters.
This requires us to find/use social cleavages (e.g., left-right, gender, secular vs. religious, urban-rural, and center-periphery) and to identify major groups for a country.
As intuitive as it is, a distance measure cannot capture the within-group distribution aspect of polarization: polarization is not only a function of the distance between the mean positions of two groups, but also of how concentrated/dispersed the attitudes are within each group – a system is not that polarized even with a large between-group distance as long as voters among each group are widely dispersed in the policy space (to the point of a great overlap between two groups).
Second, there are variation measures that capture variance among individuals or parties; however, as @mehlhaff2022group points out, high variance does not necessarily imply polarization or bimodality.
Third, there are measures for bimodality; but there is no true test for bimodality; the most used Kurtosis measure has been shown to have no relationship with bimodality at all [@westfall2014kurtosis,@mehlhaff2022group].
Finally, a much more recent and comprehensive measure is @mehlhaff2022group’s cluster-polarization coefficient (CPC): intuitively, this measure, bounded between 0 and 1, takes into account both dynamics of polarization – it increases when the distance between clusters increases or when clusters become more tightly concentrated around their centroid.^[This measure can also accommodate more than one dimension of social cleavages.]

To generate polarization estimates, we will revise and expand the DCPO model and relevant packages to identify and aggregate subpopulation opinions.
Although existing studies usually focus on partisan polarization, polarization exists across different subgroups.
We will estimate polarization between ideological left and ideological right, female and male, urban and rural, and religious and secular.

To this end, we will first revise DCPOtools to automatically collect and process ancillary data on population characteristics based on our expanded source data.
Secondly, we will develop the DCPO model and package to estimate public opinion within subpopulation groups and then the cleavage of opinion between subpopulation groups.

<!--Need more infor here.  maybe encounter more DN or missing data for certain groups.   -->



*Disseminating the resulting estimates.*

We will achieve broad dissemination through conference presentations, scholarly publications, software, dataverse, and a user-friendly web interface.
Over the two-year period, we will attend multiple conferences, including but not limited to the Annual Meetings of the American Political Science Association (APSA), the International Studies Association (ISA), and the Midwest Political Science Association (MPSA).
In the first year, we will present our work in progress to attain scholarly suggestions and feedback to improve our model and substantive work.
In the second year, we will disseminate our estimates by introducing our packages and dashboard as well as presenting our substantive results.

Specifically, during the first year, we will focus on the estimates of public opinion by extensively expanding raw source data and survey items, including environment-related questions and respondents' demographics.
Our first scholarly article will focus on measures of public opinion on climate change and their validations through both convergent validation and construct validation.
According to @adcock2001measurement, convergent validation compares a given indicator with another indicator of the same concept, while construct validation assesses whether a given indicator is empirically correlated with other indicators in a way that conforms to theoretical expectations.
We will conduct an "internal" test [@caughey2019policy,@woo2023measuring] comparing climate attitudes to responses to individual survey items.
For example, we will look at the percentage of respondents who agree to some extent that climate change should precede economic growth and that climate change is a threat, or their public stance on supporting relevant policies and government efforts to mitigate climate change.
For construct validation, we plan to test the relationship between climate attitude and exposure to disasters.

In the second year, we will update the DCPO packages to measure polarization in climate change attitudes across different subpopulation groups across countries over time.
The second scholarly article will focus on measures of polarization on public opinion on climate change.
We will introduce our models to measure polarization.
To validate our measures, we will compare them with measures from alternative polarization measuring approaches.
For example, xxxxxxx

Meanwhile, we will apply these estimates to study the dynamic relationship between climate change attitudes, polarization, and climate-policy adoption in cross-sectional time-series data.
The third paper examines how public climate change concerns and policy preferences impact climate policy adoption. 
Using our measures of public opinion and polarization, we will analyze the relationship between public opinion and climate policy adoption across countries over time.
We will use data from the Climate Change Laws of the World [@nachmany2017global], which compiles laws and regulations aimed at reducing carbon emissions and promoting clean energy.
The main outcome variable is the number of new climate policies adopted per country-year, with the previous year's cumulative climate policies as a control variable.
This approach tests  how current levels of public concern about climate change contribute to the existing level of climate laws and regulations.^[
We will control for GDP per capita (log), oil rent (% of GDP), coal rent (% of GDP), and CO2 emissions per capita using World Development Indicators (WDI).
Political regime effects will be controlled using the liberal democracy variable from the V-Dem Dataset.
To account for the impact of climate-related natural disasters on policy adoption, we will use data from the Emergency Events Database (EM-DAT), which includes global natural disaster data.
For empirical analysis, we will employ a two-way fixed effects model with robust standard errors at both time and entity levels to control for unobserved heterogeneity in panel data.]
Additionally, the PIs will take advantage of conference time for in-person, in-depth project meetings to exchange ideas and set the agenda.

Beyond conference presentations and three scholarly publications, we will disseminate our data through Dataverse, provide two updated DCPO packages, and develop a user-friendly dashboard.
Climate scholars can download our estimates directly from Dataverse for use in downstream analyses.
The updated DCPO packages will enable scholars to measure public opinion of their interests, from data collection and data wrangling to generating estimates.
The user-friendly dashboard will be a valuable tool for the general public to explore temporal trends and compare spatial differences in public climate change attitudes, allowing users to visualize data based on their preferred time period, demographics, country, or region.


# Timeline and Project Implementation
We propose a two-year project, estimated based on our initial efforts in collecting, cleaning, and measuring data.
To this date, we have gathered survey data from 85 countries, each with an average of 19 years of estimates.^[This is supported by a seed grant from the Center of Social Data Analytics (C-SODA) of the Penn State University, 2022-2023.]
However, there is variation in the number of years of estimates across regions. European countries have the longest data spans; for instance, 12 countries (Belgium, Denmark, France, Germany, Greece, Ireland, Italy, Luxembourg, Netherlands, Portugal, Spain, and the United Kingdom) have 31 years of estimates.
In contrast, Asian, Latin American, and African countries have fewer years of data, despite being more vulnerable to climate change due to their geographical location and state capacity in dealing with climate threats.
For example, five countries (Uganda, Ghana, Tunisia, Senegal, and Vietnam) have less than 10 years of data.

During our two-year project, we will expand the coverage of our raw data in terms of country-year and country-year-items, measure public opinion, revise and improve DCPO models to measure polarization, write up three scholarly papers and disseminate our estimates. 
Our plan for the project timeline is outlined as follows:

Summer and Fall 2025: Raw data collection.

In our first year, in addition to expand temporal coverage from latest released data, such as European Barometer and European Social Survey, we will focus on expanding our data to include single-country surveys, which are often conducted in their native languages, such as the Chinese General Social Survey (CGSS), Korean General Social Surveys, and single-country surveys not incorporated in the compiled data of the African Barometer and Latin American Public Opinion, both of which have recently released their latest 2023 survey data.
Due to language and transcription challenges, these single-country surveys usually take longer to identify, collect, and clean.

We also plan to expand our items to include both climate-relevant and environment-relevant questions.
The project team will write a codebook for item selection, train research assistances to code items, conduct inter-coder reliability tests, and update the codebook to achieve a higher level of intercoder reliability.
This process will involve several rounds of discussions and revisions, potentially extending the timeline.

Spring 2026: Estimate climate change public opinion measures and write up the first scholarly paper on measures and validations.
Once the public opinion measures are ready, as described above, we will draft our first paper on these measures and validate them.
We will present our findings and introduce our opinion data at various conferences during Spring and Summer 2026, ensuring feedback from peers.
We will publish our web interface, making the opinion data available for download and user interaction.

Summer 2026: Revise DCPO models and packages for estimating polarization; collect demographic information from survey data for measuring polarization.
During the summer, we will collect demographic information from surveys, including but not limited to gender, ideology, residence, and religion.
This information will be essential for subgroup opinion measures.
We will revise our DCPO models to measure climate change opinion within subpopulations and assess differences, such as comparing climate opinion between male and female. 

Fall 2026:: Estimate climate change polarization through various approaches, compare polarization measures, and draft a paper on climate change polarization estimates and validations.
Although existing methods of measuring polarization cannot address gaps in time-series data, we can use them when data is available and compare their results with our methods, which can smooth time-series data.
Based on our findings, we will write up our second paper about polarization measures. 

Spring 2027: Finalize data collection for dynamic analysis up to recent years and conduct analysis on the relationship between public opinion, polarization, and policy outputs.
We will finalize the data collection required for our dynamic analysis, ensuring it covers the most recent years.
We will then analyze the relationships between public opinion, polarization, and policy outputs.
We will present our polarization measures and preliminary analysis for the third paper at academic conferences.
Our polarization measures will be added to our web interface. 
We will enhance data visualization, online analysis, and provide customized functions for users at our web interface.

Summer 2027: Write up the paper about dynamic relationship between climate public opinion and climate policies.

# Broader Impacts
The Climate Change Public Opinion Dataset (CCPOD) will serve as a crucial research infrastructure for researchers, educators, students, policymakers, non-governmental organizations, and news agencies worldwide, fostering both within and cross-national work on climate change, polarization, and broader public opinion.
Through conference presentations, scholarly publications, and a user-friendly web interface, the dissemination of the resulting estimates will enhance the understanding of scholars, policymakers, and general audience (like NGOs and Journalists) about the relationship between public opinion and climate policies, ultimately contributing to more informed and effective climate change action.
In addition, two open-source R package for automatically data collection and measurement are made available so others can analyze similar data.
This aligns with NSF’s commitment to making knowledge accessible to policymakers, the public, and researchers.
Moreover, this project will promote teaching by providing CCPOD's web-based graphical interface with user-friendly functionality to facilitate its use for teaching and learning data analytics and by employing graduate research assistants, especially members of marginalized groups, who will develop valuable new skills in this important interdisciplinary field.

# Results From Prior NSF Support
Co-PIs Cao and Tai have received no prior NSF support.
Solt was PI of NSF Award Number 1533746, "Standardized World Income Inequality Database" (SWIID) which was successfully completed in 2019.
The project resulted in the publication of @Solt2020, which is listed by the Web of Science _Essential Science Indicators_ as a Highly Cited Paper, among the top 1% most cited articles in the social sciences (excluding economics) for its year of publication; biannual updates to the SWIID on the Harvard Dataverse each year since 2017 that collectively have been downloaded more than 150,000 times; and the SWIID website, which provides a user-friendly interface to the dataset and receives in excess of 100 visitors daily.







\newpage

## References

\indent
\setlength{\parindent}{-.5in}
\setlength{\leftskip}{0.5in}








