---
title: |
  | Collaborative Research: 
  | Public Opinion Regarding Climate Change
subtitle: | 
  | Measuring Public Concern and Polarization
  | Across Countries and Over Time
  |
  | Project Description
date: "\\vspace{-7em}"
csl: american-political-science-association.csl
output: 
  pdf_document:
    includes:
    extra_dependencies: ["float"]
    template: null
    keep_tex: no
    number_sections: false
documentclass: nsf2
bibliography: references.bib
biblio-style: apalike
header-includes:
      - \usepackage{times}
      - \usepackage[fontsize=12pt]{scrextend}
      - \usepackage{wrapfig}
      - \date{\vspace{-10em}} 
      - \renewcommand{\topfraction}{.85} # Adjust LaTeX placement rules per 
      - \renewcommand{\bottomfraction}{.7} # https://bookdown.org/yihui/rmarkdown-cookbook/figure-placement.html
      - \renewcommand{\textfraction}{.15}
      - \renewcommand{\floatpagefraction}{.66}
      - \setcounter{topnumber}{3}
      - \setcounter{bottomnumber}{3}
      - \setcounter{totalnumber}{4}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  dpi = 600,
  fig.width = 7,
  fig.height = 4,
  plot = function(x, options)  {
    hook_plot_tex(x, options)
  }
)

if (!require(pacman))
    renv::install("pacman")
if (!require(DCPOtools))
    p_install_gh(c("fsolt/DCPOtools"))
library(pacman)
library(DCPOtools)
library(tidyverse)
library(here)
library(RColorBrewer)
library(patchwork)
library(DCPOtools)
```

```{r dcpo_input_raw_cc2, eval=FALSE}
surveys2 <- read_csv(here::here("data-raw", "surveys_cc_add.csv"),
                     col_types = "ccccccc")

dcpo_input_raw_cc2 <- DCPOtools::dcpo_setup(surveys2,
                                            file = here::here(
                                              "data-raw",                                                              "dcpo_input_raw_cc2.csv"))
```

```{r cc_summary_stats}
surveys2 <- read_csv(here::here("data-raw", "surveys_cc_add.csv"),
                     col_types = "ccccccc")

surveys <-  read_csv(here::here("data-raw", "climate_index_cli.csv"),
                       col_types = "cccc")[c(1:26,29:141,145:455,458:480),] %>% 
  bind_rows(surveys2)

dcpo_input_raw_cc2 <- read_csv(here::here("data-raw",
                                          "dcpo_input_raw_cc2.csv"),
                               col_types = "cdcddcd")

dcpo_input_raw_cc0 <- read_csv(here::here("data-raw",
                                         "dcpo_input_raw_cc.csv"),
                               col_types = "cdcddcd") %>% 
  filter(!survey %in% c("eb672", "eb692", "eb621")) %>% # don't double-count
  bind_rows(dcpo_input_raw_cc2)

with_min_coverage <- function(x, min_cov) {
  if (!is.na(min_cov)) {
    country <- year <- years <- spanned <- coverage <- NULL
    x <- x %>%
      group_by(country) %>%
      mutate(years = length(unique(year)),
             spanned = length(min(year):max(year)),
             coverage = years/spanned) %>%
      filter(coverage >= min_cov) %>%
      select(-years, -spanned, -coverage) %>%
      ungroup()
  }
  return(x)
}
with_max_gap <- function(x, max_gap, edges = TRUE) {
    if (!is.na(max_gap)) {
        country <- yr_obs <- NULL
        c_yrs <- x %>% 
            group_by(country, year) %>% 
            summarize(year = first(year)) %>% 
            mutate(lead_span = ifelse(!is.na(lead(year)),
                                      lead(year) - year - 1,
                                      50),
                   lag_span = ifelse(!is.na(lag(year)),
                                     year - lag(year) - 1,
                                     50),
                   min_span = pmin(lead_span, lag_span),
                   max_span = pmax(lead_span, lag_span),
                   drop = min_span > max_gap & max_span == 50)
        
        x <- x %>% 
          left_join(c_yrs,
                    by = c("country", "year")) %>% 
          filter(!drop) %>% 
          select(-contains("span")) %>% 
          select(-drop)
    }
    return(x)
}

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
  dcpo_input_raw_df %>% 
    with_min_yrs(3) %>% 
    with_min_cy(5) %>% 
    with_min_yrs(3) %>% # double-check after dropping <5 cy
    filter(year >= 1972 & n > 0 & country!="German Democratic Republic") %>% # see https://github.com/fsolt/DCPOtools/issues/62 re GDR--filtering out here is a quick-and-dirty fix
    group_by(country) %>% 
    mutate(cc_rank = n()) %>% 
    ungroup() %>% 
    arrange(-cc_rank)
}

dcpo_input_raw_cc <- process_dcpo_input_raw(dcpo_input_raw_cc0)

n_surveys <- surveys %>%
  distinct(survey) %>% 
  nrow()  

n_items <- dcpo_input_raw_cc %>%
  distinct(item) %>% 
  nrow() 

n_countries <- dcpo_input_raw_cc %>%
  distinct(country) %>% 
  nrow()  

n_cy <- dcpo_input_raw_cc %>%
  distinct(country, year) %>% 
  nrow() %>% 
  scales::comma() 

n_years <- as.integer(summary(dcpo_input_raw_cc$year)[6]-summary(dcpo_input_raw_cc$year)[1]) 

spanned_cy <- dcpo_input_raw_cc %>% 
  group_by(country) %>% 
  summarize(years = max(year) - min(year) + 1) %>% 
  summarize(n = sum(years)) %>% 
  pull(n) %>% 
  scales::comma() 

total_cy <- {n_countries * n_years} %>% 
  scales::comma()  

year_range <- paste("from",
                    summary(dcpo_input_raw_cc$year)[1], 
                    "to",
                    summary(dcpo_input_raw_cc$year)[6]) 

n_cyi <- dcpo_input_raw_cc %>% 
  distinct(country, year, item) %>% 
  nrow() %>% 
  scales::comma() 

back_to_numeric <- function(string_number) {
  string_number %>% 
    str_replace(",", "") %>% 
    as.numeric()
}
covered_share_of_spanned <- {back_to_numeric(n_cy)/
    back_to_numeric(spanned_cy) * 100} %>%
  round()

top_country_cyi <- dcpo_input_raw_cc %>% 
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(-n) %>% 
  slice_head() %>%
 pull(country) 

top_country_cyi_obs <- dcpo_input_raw_cc %>%
  filter(country == top_country_cyi) %>%
  distinct(country, year, item) %>%
  nrow()  

others_cc <- dcpo_input_raw_cc %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(desc(n)) %>%
  slice(2:5) %>%
  pull(country) %>% 
  paste(collapse = ", ") %>% 
  str_replace(", (\\w+)$", ", and \\1") # "Germany, France, Spain, and Italy""

y_cc_peak_year <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(year) #2019

y_cc_peak_nn <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>% 
  filter(nn == max(nn)) %>% 
  pull(nn) %>% 
  first() #116 countries in 2019

data_cc_poorest <- dcpo_input_raw_cc %>%
  distinct(country, year, item) %>%
  count(country) %>%
  arrange(n) %>%
  filter(n < 10) %>%
  pull(country) %>% 
  paste(collapse = ", ") %>% 
  str_replace(", (\\w+)$", ", and \\1")  #Palestinian Territories, Tunisia, Uganda, Armenia, German Democratic Republic, Ghana, Pakistan, Taiwan, and Tanzania

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

n_cc_data_poorest <- {data_cc_poorest %>%
    str_split(",") %>% 
    first()} %>% 
  length() %>% 
  wordify_numeral()
```

As the NSF's current Strategic Plan observes, addressing climate change is one of the "great scientific challenges of our time" [@NSF2022, 16].
It is also, fundamentally, a political challenge.
Consider heat pumps, which work by moving heat into or out of a home depending on the season to ensure a comfortable temperature.
Heat pumps are electric and therefore as renewable energy expands increasingly zero-emission, making them a key part of decarbonization efforts; they are also so efficient that they are much cheaper to operate than fossil-fuel furnaces or boilers.
But they also cost more to buy and install.
When Germany announced last year that it would effectively prohibit the installation of new gas and oil heating systems and so ensure a gradual transition to heat pumps, the resulting public backlash was so intense it forced the government to delay and water down its effort to even begin to decarbonize home heating, the source of one-sixth of the country's carbon emissions [see, e.g., @VonDerBurchard2023].
As this example demonstrates, understanding the interplay between policy and public opinion is crucial to effectively addressing climate change.

Regardless of this crucial need, data issues have hindered efforts to understand the extent and causes of the public's demand for action on climate, the conditions in which governments act on these demands, and how public opinion responds when they do.
Cross-national survey data on attitudes toward climate change, as on other topics, is sparse, incomparable, or most often both.
That is, survey data is unavailable for many countries and years, and, even when relevant surveys exist, the multiple different questions asked make putting all of the information to use in any comparative study difficult [see, e.g., @Caughey2019; @Solt2020c].

These difficulties are so severe as to lead many researchers to give up on measuring public opinion entirely and rely instead on proxies such as media coverage of climate issues [e.g., @Schaffer2022].
To enable research that will successfully allow policymakers to navigate the politics of climate change, there is a critical need for better data on public opinion. 

This proposal's objective is to address this need.
The approach is to collect all of the data on climate-change attitudes available in national, regional, and global surveys and then use computational social science methods, specifically Bayesian latent-variable models, to overcome their sparsity and incomparability.
Bayesian latent-variable models have emerged as a powerful tool for generating comparable estimates of the trends in the mean of public opinion over many years in many countries [see, e.g., @Caughey2019; @Woo2023; @Hu2024].
Growing scholarly and popular attention to political polarization suggests, however, that mean attitudes alone may be insufficient to capture important features of public opinion: concentrated opposition or divisions that fall along existing social cleavages may be at least as important.
This project will therefore build on one of these latent-variable models, the Dynamic Comparative Public Opinion (DCPO) model introduced by @Solt2020c, to expand its output to measures of polarization.
Applying this expanded model to the collected surveys will yield the Climate Change Public Opinion Dataset (CCPOD), which will serve as critical infrastructure for research on the causes and consequences of climate change attitudes in the public of countries around the world.
The CCPOD will advance knowledge about the world and inform policymakers as they seek effective policy solutions in the fight against climate change.

### Background
There is a large existing literature that explains public opinion on climate change (e.g., citizen knowledge, attention, concern for climate change as well as policy preferences), especially in developed economies.
For instance, many have shown that extreme weather events (e.g., droughts, wildfires, and hurricanes) triggered by climate change increase public climate change concerns and preferences for mitigation policies.
This scholarly enthusiasm to explain climate public opinion is underpinned by an underlying assumption that one needs public support to produce climate policies to combat climate change; in other words, public opinion matters in the realm of climate policies.
But does it? More specifically, would public opinion on climate change affect national climate change policy outputs?
Surprisingly, the literature is silent when it comes to this obvious and yet extremely important question.
The reason for this is simple and yet it presents a great challenge for the research community: there is no systematic data on cross-country public opinion regarding climate change. 

With the threats of climate change increasingly realized, it is vital to understand climate policies and politics.
Existing theories on these subjects largely focus on collective action and distributive politics, ignoring the potential impact of public sentiment.
Collective action theory treats carbon mitigation as a global public good, with the free-riding behavior of many countries the core challenge [@Ostrom1990; @Barrett2003; @Nordhaus2015; @Keohane2016].
However, it fails to explain why some countries are more proactive and less inclined to free-ride in mitigation efforts than others.
Distributive politics, on the other hand, views climate policy as a battleground for interest groups, some of which would lose while others might gain from climate mitigation [@Colgan2021; @Aklin2020].
Owners of so called "climate-forcing" assets (those generating large amounts of carbon emissions) stand to lose with stringent mitigation policies and have been a large barrier to effective climate policy.
One key question that remains to be answered is whether pro-mitigation public preferences can outweigh these anti-mitigation forces.
<!--The key question is: (how) does public opinion influence climate policy?-->

Traditional wisdom suggests that public opinion influences public policy through government responsiveness [@Dahl1971], a dynamic observed even in authoritarian countries [@Alkon2018; @Miller2015; @Meng2017].
In @Burstein2003's influential review on public opinion and policy, it was found that while public opinion often strongly influences policy, most studies focus on the United States and a few West European countries, with minimal attention to developing countries.
According to the Web of Science, since 1990, there have been 1,829 articles on the environment or climate change and public opinion, with 306 focused on the United States, 128 on China, 114 on the EU, 38 on Africa, and 15 on Latin America.
Narrowing the scope to cross-national research reduces the count to 28.
Among these, most studies have examined the determinants of environment/climate attitude and the determinants of climate policies independently [@Stenner2015; @Papiez2018; @Fankhauser2014; @Hao2021]; few consider the role of public opinion in affecting environmental and climate policy outputs: here only proxy measures of climate public opinion (e.g., using environmental rather than climate attitudes or media coverage of climate issues) are used [@Anderson2017; @Bakaki2020; @Schaffer2022]. 

Again, cross-national analyses overlook the role of public opinion due to data limitations.
Even for broader attitudes towards environmental issues, comprehensive multi-decade, cross-national surveys are lacking [@Von2022]. @Anderson2017 found a positive relationship between public environmental attitudes (using Eurobarometer data) and renewable energy policy outputs in Europe from 1974 to 2015.
Similarly, @Bakaki2020 identified a triangular relationship between citizens' environmental concerns, media attention, and renewable policy output in six European democracies from 1983 to 2012.
The limited spatial coverage is primarily due to the lack of data.
The situation is even more severe for climate change attitudes.
Due to the absence of comparative climate opinion data, @Schaffer2022 used media coverage of climate issues as a proxy for public concerns in studying climate change mitigation in six OECD countries over a period of 1995-2010, even though this measure has low validity given its low correlation (r = 0.27) with climate public opinion data [@Oehl2017] and the paper itself acknowledges that "public opinion surveys arguably provide the most direct measure of public demand" [see, @Schaffer2022, 137].

In addition to the average level of public climate concern, how such concerns are distributed within a society, especially along with existing salient social cleavages---partisan lines, urban-rural divide, and gender differences, to name but a few---is equally if not more important for climate policies.
Polarization in climate concerns captures the intuition that significant differences in views and preferences towards climate issues exist and likely increase between different groups of people in a society.
It is an important concept with profound policy implications.
Addressing the climate challenge requires a transformation of our societies and this scale of change depend upon far-reaching reforms from governments that many believe are only possible when there is a widespread social and political support for such a transition.
Increasing political polarization of climate policy-relevant attitudes would inhibit such climate reforms.
It signifies popular disagreement on issues surrounding climate policies and provide fertile grounds for political mobilization that often blocks necessary reforms.
Therefore, many believe that political polarization of public attitudes relevant to climate change presents a challenge for not only the implementation but also the durability of climate reforms.



Even though we have seen no systematic, large-N analysis studying the effect of polarization on climate policies in a cross-country context, there are many studies connecting polarization to important political and policy outputs and outcomes in other issues areas. For instance, some have argued that polarization affects government accountability [@Jones2015;@Bornschier2019]; others have shown that polarization can make party brands more visible, therefore helping voters with clearer choices during elections [@Lupu2015; @Singer2016].
At the same time, polarization might also result in instability in legislative process and democratic backsliding [@Mccoy2019;@Stavrakakis2018].
Elsewhere, @Iversen2015 discover a negative correlation between mass polarization and income inequality; they argue that in the context of advanced economies such a correlation is a function of political information available to voters.
Using data from the 1999 European Election Study and an expert survey on party positions, @Lachat2008 shows that the role of citizens' left–right orientations in affecting voting behaviors increases with party system polarization.
@Lindqvist2010 find that political polarization is strongly associated with smaller government in democracies, but there is no such relationship in undemocratic countries.^[Though they acknowledge that multiple explanations exist for a connection between polarization and government spending, and they can point to different directions (e.g., polarization could lead to conflicts of interest among the poor that affect their ability to form coalitions for increased redistribution).]

Also, the study of polarization is not limited to the case of the United States---even though the country is the subject most of the studies on the topic largely because of its rich data.
Other regions of the world, even countries outside the advanced economies, have seen an increasing number of studies on polarization. For instance, @Church2016 highlight the extreme polarization of public opinion as the first of the five most important changes reshaping Swiss politics today.
Still in Western European context, @Moral2017 shows that high party polarization increases voter turnout for both politically sophisticated and unsophisticated citizens, using individual and party system-level data from 17 European multiparty democracies.
@Evans2002 test the effectiveness of competing explanations of ethnic polarization in attitudes towards minority rights in 13 East European societies; they find that cultural differences explain polarization not only at the individual, but also regional and cross-national levels.
In an Asian context, @Slater2018 present a comparative analysis of polarizing crises in five Asian democracies; they show what explains crisis severity and resolution is not traditional fault lines between left and right, rich and poor, and secular and religious, but how the leading elite opponents of polarizing figures managed their removal from office. 
@Singer2016 shows that in developing democracies such as those in Latin America, political polarization increases representation because it helps parties better differentiate themselves from each other and make it easier for voters to see the connection between their personal ideologies and the electoral offerings. 

Public opinion on climate change has become increasingly complex during times of polarization.
Yet, when we zoom in on polarization in climate change, we find that past studies often focus on the case of the United States, they are descriptive in nature, and no study has tested the effect of polarization on climate policies in a cross-country setting.
Indeed, in the United States, climate change is a deeply divisive and politicized issue, with political ideology significantly influencing attitudes towards climate and environmental policies [@Mccright2011; @Czarnek2021;@Jasny2015].
For instance, liberals generally show greater support for climate change policies than conservatives [@Boudet2020; @Hazlett2020; @Mccright2016; @Egan2017; @Merkley2018].
This polarized view on climate change can be traced all the way back to the early 1990s.
Since then, Americans’ climate attitudes have become more and more strongly associated with their partisan and ideological affiliations.
Many attribute this trend of polarization to the influence of conservative political elites’ climate denial campaigns upon Republican voters [@Tesler2018]. 
Whether similar levels of climate polarization have occurred in other countries, however, remains an open question.
It seems that climate attitude polarization (based on political party affiliations for example) does exist in other English-speaking countries including Australia, Canada, and the UK [@Lachapelle2012; @Tranter2013; @Kenny2024] as well as in some western European countries such as Switzerland [@Luth2022].
Yet, there is no evidence that such polarization exists in Eastern European countries [@Fisher2022] and as far as we know, no study has looked at polarization in climate change public opinion beyond North American and European countries.   

There are at least three major obstacles that prevent the study of climate public opinion polarization in a cross-country setting.
First, other than partisan polarization, other social divides such as gender, race, education, income, and socioeconomic status also influence public climate attitudes, as shown in various cross-national studies [@Lewis2019; @Pearson2017; @Hornsey2016; @Lee2015].
For instance, women in wealthier countries in the Americas and Europe are more likely to be concerned about climate change than men, possibly because men perceive higher costs in climate mitigation policies since they benefit more from the current hierarchical political and social system [@Bush2023]. Identifying (most) relevant fault lines that divide public opinion in cross-country setting is challenging because one needs country-specific knowledge regarding key social cleavages.
Second, one needs survey data with individual-level variables that measure these cleavages, and these surveys also need to include questions on climate change concerns.
Once we move out of advanced countries, such surveys become less common. Finally, there are various ways to measure polarization and there is no concensus regarding which approach is better in general and in our context of climate change attitude polarization.

It is well documented that comparative public opinion studies have been hampered by the lack of comprehensive data, not to mention public polarization data.
The scarcity of comparative data at the aggregate level is due to data sparseness and fragmentation, with many countries and years lacking data, and existing data often being incomparable due to differences in items and interpretations.
However, an emerging group of scholars has been dedicated to developing models to measure comparative public opinion across countries over time [see, e.g., @Caughey2019; @Solt2020c; @Kolczynska2024].
Among these, the Dynamic Comparative Public Opinion model [DCPO, @Solt2020c] has been widely used to measure comparative public opinion and has successfully created comparative data for views on gender equality in politics and the workplace [@Woo2023], political interest [@Hu2024], and attitudes toward gay rights [@Woo2024].

```{r pocc-plot, fig.cap="Countries and Mean Years Observed in Prominent Research\\label{pocc_plot}", fig.height=4.5, fig.width=7.5, fig.pos='h', cache=FALSE}

cited <- tribble(~citation, ~text_x, ~text_y,
                 "Clements and Field 2014", 8.8, 42,
                 "Yang 1997", 4.7, 26,
                 "Hildebrandt et al. 2019", 72, 0,
                 "Adamczyk and Pitt 2009", 40, -.5,
                 "Reynolds 2013", 80.7, 2.9,
                 "Redman 2018", 65.5, 2.9,
                 "Hooghe and Meeusen 2013", 37.6, 4.24)

pocc <- read_csv(here::here("data-raw", "savedrecs.csv"),
                 show_col_types = FALSE) %>% 
  bind_rows(read_csv(here("data-raw", "savedrecs_gs.csv"),
                     show_col_types = FALSE) %>% 
              select(-`End Page`)) %>% 
  janitor::clean_names() %>% 
  mutate(year = publication_year,
         hits = times_cited_all_databases,
         last_names = str_remove_all(authors, ", [A-Z]{1,3}") %>% 
           str_to_title() %>% 
           str_replace_all(";", ",") %>% 
           {ifelse(str_count(., ",") > 1,
                   str_replace(., ",.*", " et al."),
                   .)} %>% 
           str_replace(", ([A-Z][a-z]+)$", ", and \\1") %>% 
           str_replace("^([A-Z][a-z]+(?:-[A-Z][a-z]+)?), and ([A-Z][a-z]+)$", "\\1 and \\2"),
         citation = paste(last_names, year),
         cy = k*t) %>% 
  group_by(k, t) %>% 
  mutate(to_jitter = n() > 1) %>% 
  ungroup() %>% 
  filter(!is.na(k) & k > 0)#%>% 
    # left_join(cited, by = "citation")

my_palette <- colorRampPalette(brewer.pal(11, "Spectral"))
color_scale <- scale_color_gradientn(colors = my_palette(max(pocc$year) -
                                                             min(pocc$year) + 1),
                                     limits = c(min(pocc$year),
                                                max(pocc$year)),
                                     name="Publication\nYear")
fill_scale <- scale_fill_gradientn(colours = my_palette(max(pocc$year) -
                                                            min(pocc$year) + 1),
                                   limits = c(min(pocc$year),
                                              max(pocc$year)),
                                   name="Publication\nYear")

set.seed(324)
pocc_plot <- ggplot(pocc, aes(x = k,
                            y = t,
                            color = year,
                            fill = year)) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(!to_jitter),
               alpha = .75) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(to_jitter),
               alpha = .75,
               position = position_jitter(width = .25, height = .25)) +
    # geom_text(aes(label = citation,
    #               x = text_x,
    #               y = text_y,
    #               size = 35),
    #           data = pocc %>% filter(!is.na(text_x)),
    #           color = "grey20") +
    color_scale +
    fill_scale +
    theme_bw() +
    theme(legend.justification = c(.99,.99), 
          legend.position = c(.98,.98),
          legend.box.background = element_rect(color = "grey",
                                               fill="white"),
          legend.box="horizontal") +
    scale_size(name = "Citations") +
  coord_cartesian(xlim = c(0, 125), ylim = c(0, 20)) +
    labs(x = "Countries Observed",
         y = "Mean Years Observed Per Country Observed",
         title = "Prominent Articles on\nPublic Opinion on Climate Change") +
  annotate(geom = "rect", 
           xmin = 0, xmax = 5, 
           ymin = 0, ymax = 5,
           color = "black", 
           fill = NA,
           linewidth = .25 ) +
  geom_segment(aes(x = 0, y = 5, xend = 19.4, yend = 19.4),
               linetype = "dashed",
               color = "gray",
               linewidth = .25) +
  geom_segment(aes(x = 5, y = 0, xend = 70, yend = 4.5),
               linetype = "dashed",
               color = "gray",
               linewidth = .25)

set.seed(324)
zoom_plot <- ggplot(pocc, aes(x = k,
                            y = t,
                            color = year,
                            fill = year)) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(!to_jitter),
               alpha = .75) +
    geom_point(aes(size = hits),
               data = pocc %>% filter(to_jitter),
               alpha = .75,
               position = position_jitter(width = .25, height = .25)) +
    # geom_text(aes(label = citation,
    #               x = text_x,
    #               y = text_y,
    #               size = 35),
    #           data = pocc %>% filter(!is.na(text_x)),
    #           color = "grey20") +
    color_scale +
    fill_scale +
    theme_bw() +
    theme(legend.position = "none",
          plot.background = element_rect(colour = "black",
                                         fill = "white",
                                         linewidth =.5)) +
    coord_cartesian(xlim = c(0, 5), ylim = c(0, 5)) +
    labs(x = NULL,
         y = NULL)

pocc_plot + 
    inset_element(zoom_plot, 15/80, 10/40, 44/80, 37/40) +
    plot_annotation(caption = str_wrap("Note: Citation counts as reported by the Web of Science on June 15, 2024.", 
                                       width = 114))
```

Regarding climate change public opinion, we first explored the country-year coverage of climate-change questions in existing surveys and the literature.
Figure\nobreakspace{}\ref{pocc_plot} shows how the available data have influenced scholarship on the topic.
Using the Web of Science and Google Scholar, we assembled a sample of prominent published articles on public opinion toward climate change.^[
Web of Science topic searches return articles in which the search terms appear in the title or abstract.
We executed the following search: `TS=("public opinion" AND ("climate change" OR "global warming" OR "greenhouse effect"))`.
The fifty most-cited empirical research articles returned were retained.
Google Scholar, [according to its about page](https://scholar.google.com/intl/en/scholar/about.html), "aims to rank documents the way researchers do, weighing the full text of each document, where it was published, who it was written by, as well as how often and how recently it has been cited in other scholarly literature."
We searched `"public opinion" "climate change"` and identified the first fifty articles returned.
Then we added the Web of Science records for the Google Scholar results (to ensure consistency of citation counts) to our original Web of Science sample and dropped all duplicates, yielding a total of `r nrow(pocc)` different articles.]
These articles had publication dates as early as `r summary(pocc$year)[[1]]` and as late as `r summary(pocc$year)[[6]]` (median: `r summary(pocc$year)[[3]]`) and were cited in the Web of Science from `r summary(pocc$hits)[[1]]` to `r summary(pocc$hits)[[6]]` times (median: `r summary(pocc$hits)[[3]]`).
We then examined these articles to find the number of countries and years investigated in each.
As the zoomed portion of the plot pocc-plot emphasizes, many of these articles might be described as using case-study or small-_n_ research designs.
Just over a third consider only a single year in a single country; together with works that study four and fewer countries and years (inset) they comprise nearly half of this sample.

<!-- reconsider this paragraph-->
In addition, climate change survey data presents distinctive challenges.
First, the data are particularly fragmented among many different survey questions due to the rapid changes in the salience of the climate change topic and specific subtopics, from climate knowledge to policy preference.
Second, an unusually large number of countries are data-poor.
<!-- plots of country-years per question across topics (climate change vs. PGE vs. macrointerest, for example).-->
Moreover, regarding climate-change opinion, researchers are particularly interested in _polarization_ in attitudes, but existing latent-variable solutions have paid little attention to this.

The lack of extensive cross-sectional time series data on public opinion and polarization regarding climate change significantly impedes research in the fields of opinion and climate policy.
Our project aims to expand both the geographic and temporal dimensions and contribute to the literature on public opinion, polarization, and policy outcomes related to climate change policies.


### The Proposed Research
The proposed research comprises four principal activities: (1) _collecting the available survey data_ on climate change, (2) _generating mean estimates_ for public opinion on climate change, (3) developing and testing a range of methods for _generating estimates of polarization_ in public opinion on climate change, and (4) _disseminating the results_ to researchers, educators, students, and policymakers worldwide through conference presentations, scholarly publications, open-source software, and a web interface.

*Collecting the available survey data.* 
To date, the project investigators have collected data on climate change opinion from over 150 survey datasets.
Nearly all of these datasets are regional (e.g., the Afrobarometer, Eurobarometer, and Latinobarometer surveys) or global (e.g., the Pew Global Attitudes surveys, the International Social Survey Program's Environment module, and the Lloyd’s Register Foundation World Risk Poll) in scope.
Together they provide information about `r n_countries` countries with an mean of `r round(back_to_numeric(n_cy)/n_countries)` years observed.^[
This data collection was supported by a seed grant from the Center of Social Data Analytics (C-SODA) at Pennsylvania State University, 2022-2023.]
From a somewhat optimistic standpoint, there are `r n_cy` country-years in which the data already collected provide at least _some_ information about attitudes toward climate change, that is, some `r round(covered_share_of_spanned)`% of the `r spanned_cy` country-years spanned by these data.
On the other hand, observations for every year since 1982 in every country surveyed would number `r total_cy`; the already-collected data constitute just `r round({back_to_numeric(n_cy)/back_to_numeric(total_cy)} * 100)`% of those country-years.

Moreover, the coverage of these data are decidedly unbalanced by geographical region.
The United States and `r wordify_numeral(dcpo_input_raw_cc %>% distinct(country, year) %>% count(country) %>% filter(n >= 20) %>% nrow() - 1)` European countries are observed in twenty or more years.
In contrast, Asian, Latin American, and African countries have fewer years of data, despite being more vulnerable to climate change due to their geographical location and state capacity in dealing with climate threats.
Three years of observations are the minimum required for a country to remain in the dataset, and the data for some `r dcpo_input_raw_cc %>% distinct(country, year) %>% count(country) %>% filter(n == 3) %>% nrow() %>% wordify_numeral()` countries---all in Africa or Asia---just meet this requirement.

```{r itemcountry, fig.cap="Countries and Years with the Most Observations in the Source Data \\label{item_country_plots}", fig.height=3.5, fig.width=6, fig.pos='h', cache=FALSE}
countries_plot <- dcpo_input_raw_cc %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country)) %>% 
  distinct(country, year, item) %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95, size = 7),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Year-Items\nObserved") +
  ggtitle("Countries")


cby_plot <- dcpo_input_raw_cc %>%
  mutate(country = if_else(stringr::str_detect(country, "United"),
                           stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                           country),
         country = stringr::str_replace(country, "South", "S.")) %>% 
  distinct(country, year) %>%
  count(country) %>% 
  arrange(desc(n)) %>% 
  head(12) %>% 
  ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  ylab("Years\nObserved") +
  ggtitle("Countries")

ybc_plot <- dcpo_input_raw_cc %>%
  distinct(country, year) %>%
  count(year, name = "nn") %>%
  ggplot(aes(year, nn)) +
  geom_bar(stat = "identity") +
   scale_x_continuous(
    minor_breaks = seq(1989, 2023, by = 1),
    breaks = seq(1980, 2024, by = 4), limits = c(1980, 2024))  +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95, size = 6),
        axis.title.y = element_text(size = 9),
        plot.title = element_text(hjust = 0.5, size = 11)) +
  xlab("Year") +
  ylab("Countries\nObserved") +
  ggtitle("Year")

world_map <- map_data("world") %>% 
  filter(!long > 180)

cby_map <- world_map %>% 
  distinct(region) %>% 
  mutate(country = countrycode::countrycode(region,
                                            "country.name",
                                            "country.name")) %>% 
  filter(!region=="Antarctica") %>% 
  left_join(dcpo_input_raw_cc %>% 
              count(country, year) %>% 
              count(country, name = "Years"),
            by = "country") %>% 
  mutate(Years = ifelse(is.na(Years), 0, Years)) %>% 
  ggplot(aes(fill = Years, map_id = region)) +
  geom_map(map = world_map,
           color = "white",
           size = 0.06) +
  coord_map(projection = "mollweide", 
            ylim=c(-80, 90),
            xlim=c(-170, 170)) +
  theme_void() +
  scale_fill_distiller(na.value = "gray90", 
                       palette = "Blues",
                       direction = 1) +
  ggtitle("Years Observed by Country") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position.inside = c(.05,.1),
        legend.justification = c(0,0), 
        legend.direction = "vertical") +
  scale_y_continuous(expand=c(0,0)) +
scale_x_continuous(expand=c(0,0))

cby_map + (countries_plot/ ybc_plot) + plot_layout(widths = c(3.8, 1.2))
```


The left panel of Figure \ref{item_country_plots} shows the years observed by country in the data already collected.
The upper right panel shows the top countries with the highest count of year-item observations.
The `r top_country_cyi` has `r top_country_cyi_obs` observations, followed by `r others_cc`.
The bottom right panel counts the countries observed in each year; it underscores that few observations antedate the past two decades.
Together, they demonstrate the potential for building a comprehensive cross-national time-series dataset on climate opinion while also highlighting the challenges in measuring comparative public climate data, including the variation in data availability geographically and temporally. 

Figure \ref{obs_by_cy} shows the distribution of these data across countries and years as a heatmap.
The x-axis represents time, and the y-axis represents space; country-years for which more distinct survey items are available appear in darker colors.
The most data-rich countries appear at the top; data grow more scarce in the countries toward the bottom.
The imbalances in coverage over time, with data over in the past two decades much richer than in preceding years, and space, with the United States and many European countries having considerably more data than countries in other parts of the world, is readily evident.

```{r obs_by_cy, fig.height = 9, fig.width = 6.5, fig.cap = "Source Data Observations by Country and Year \\label{obs_by_cy}"}
dcpo_input_raw_cc %>%
  mutate(country = str_replace(country, "'", "'")) %>%
  distinct(country, year, item, cc_rank) %>%
  group_by(country, year) %>%
  summarize(n = n(),
            cc_rank = cc_rank) %>%
  ungroup() %>%
  distinct() %>%
  ggplot(aes(x = year,
             y = forcats::fct_reorder(country, cc_rank),
             fill = n)) +
  geom_tile() +
  scale_fill_stepsn(colors = rev(hcl.colors(5, "inferno")),
                    n.breaks = 5,
                    show.limits = TRUE,
                    right = FALSE,
                    name = "Observations") +
  labs(x = NULL, y = NULL) +
  scale_x_continuous(breaks=seq(1980, 2024, 4),
                     sec.axis = dup_axis()) +
  scale_y_discrete(position = "right") +
  theme(legend.justification=c(0, 0),
        legend.position=c(0.01, 0.01),
        axis.text.y  = element_text(size = 7))
```

The data already collected are a good start, but there is clearly room for improvement.
To this end, the project will pursue two additional avenues of data collection: single-country surveys and surveys that are not publicly available.

There are many single-country surveys that include questions tapping attitudes toward climate change.
Collecting these data is a labor-intensive process for two reasons.
First, while some of these surveys, such as the U.S. General Social Survey, have been combined into time-series datasets including many years of surveys with standardized variable names, most of these surveys are scattered across datasets covering only a single year and, more often than not, inconsistent variable names.
Retrieving each of these smaller datasets, identifying the relevant questions, recording this information, and double-checking it for errors simply takes more time---at least on a country-year basis---than for consolidated cross-national or time-series projects. 
Second, most single-country surveys are housed in their respective national data archives, which naturally serve mainly researchers working in that country, with the consequence that the data, codebooks, and other supporting information are not translated into English.
As one of many examples, consider that the Finnish Social Science Data Archive contains national surveys that include climate change questions, apparently on an annual basis, dating back at least to the start of this century; all of these surveys are available only in Finnish.
Even with the assistance of online translation, the process of identifying (and confirming) the relevant survey questions is more time-consuming in such circumstances.

In addition to the single-country surveys, there is a substantial number of cross-national surveys that are not freely available.
Most important of these is the Gallup World Poll, which has frequently included climate-change questions since its 'Health of the Planet' survey conducted in 1992.
The Gallup World Poll is much employed in studies of climate-change opinion, but it is only available for download by paid subscription.
Further, many other surveys conducted by researchers (and even international organizations, such as the full datasets of the 2020 and 2024 People's Climate Vote surveys conducted by the United Nations Development Programme) have been reported in the climate-change literature but are not housed in such commonly-employed data archives as the Harvard Dataverse or the Inter-university Consortium for Political and Social Research.
Reaching out to the authors of these pieces is promising, given that norms on the free distribution of data have expanded rapidly in the past two decades, but it is nevertheless a time-consuming task.
With the support of the NSF, this resource-intensive phase of data collection can go forward.


*Generating mean estimates.*
To estimate public climate change attitudes across countries and over time, we employ the Dynamic Comparative Public Opinion (DCPO) model [@Solt2020c].^[
Other, similar models of public opinion require either very dense survey data [@Mcgann2019; @Kolczynska2024] or ancillary data on population characteristics [@Berwick2024].
The available data on climate-change opinion, as on most topics, sparse rather than dense, and reliable ancillary data is not available for the broad sample of countries considered in this project.
We are aware of one working paper that anticipates the general approach of this project under this heading, @Bergquist2024.
This project will improve on that effort by employing a much larger set of survey data and using the more recently developed DCPO latent-variable model of public opinion.]
The DCPO model is a population-level two-parameter ordinal logistic item response theory (IRT) model with country-specific item-bias terms.
It accounts for the incomparability of different survey questions with two key parameters.
First, it incorporates the _difficulty_ of each question's responses, that is, how much of the latent variable is indicated by a given response. 
That each response evinces more or less of our latent trait is most easily seen with regard to the ordinal responses to the same question: answering "extremely worried" to the question "How worried are you about climate change?" exhibits more concern than answering "very worried," "somewhat worried," "not very worried," or "not at all worried."
But this is also true across questions.
For example, responding "a great deal" to the question "how much do you think global warming will harm you personally" indicates a greater degree of concern than simply responding in the affirmative when asked "do you think that global warming is happening?"
Second, the DCPO model accounts for each question's _dispersion_, its noisiness with regard to the latent trait.
The lower a question's dispersion, the better that changes in responses to the question map onto changes in concern about climate change.
Together, the model's difficulty and dispersion estimates work to generate comparable estimates of the latent variable from the available but incomparable source data.

To address the sparsity of source data, which includes inconsistencies in the time series of each country due to unobserved country-years or limited observed items, DCPO uses local-level dynamic linear models.
These models estimate public opinion by taking the previous year's estimate and adding a random shock.
This approach smooths the estimates over time and allows for estimation even in years with little or no survey data, albeit at the expense of greater measurement uncertainty.^[
Incorporating measurement uncertainty is crucial to arriving at well-grounded conclusions [see, e.g., @Tai2024], and it is especially easy to do so in a Bayesian context [see, e.g., @Hu2024].]

To facilitate data collection, measurement, and open data science more broadly, the investigators have developed two open-source R packages: `DCPOtools` and `DCPO`.
`DCPOtools` provides standardized country and year information for each survey dataset and automates the process of collecting and wrangling the data on the needed survey items [@SoltEtAl2019].
This increases the efficiency and transparency of data processing, avoids data entry errors, and facilitates reproducibility [see @Hu2022].
`DCPO` is written in the probabilistic programming language Stan [@StanDevTeam2019b]; it uses the DCPO model to estimate latent public opinion from the survey data compiled using `DCPOtools` [@Solt2020a].
Together, these two software packages enable the investigators and other researchers to translate survey data into estimates of public opinion.


*Generating polarization estimates.*
There are different ways to measure polarization.
Indeed, scholars have been using various polarization measures, likely contributing to the disagreement regarding the identification and consequences of polarization, especially in a comparative context [@Mehlhaff2023].
The most intuitive measures are distribution or distance measures.
These measures capture the distance between the mean positions of groups: for example, the distance between the mean position of Republican voters and that of Democratic voters.
As straightforward as they are, distance measures cannot capture the within-group distribution aspect of polarization: polarization is not only a function of the distance between the mean positions of two groups, but also of how dispersed the attitudes are within each group---a system is not that polarized even with a large between-group distance as long as voters within each group are sufficiently widely dispersed in the policy space that there is considerable overlap between the two groups [see @Mehlhaff2023].
Second, there are variation measures that capture variance among individuals or parties; however, as @Mehlhaff2023 points out, high variance does not necessarily imply polarization or bimodality.
Third, there are measures for bimodality; but there is no true test for bimodality; the most used kurtosis measure has been shown to have no relationship with bimodality at all [@Westfall2014; @Mehlhaff2023].

A much more recent and comprehensive measure is the cluster-polarization coefficient (CPC) presented in @Mehlhaff2023.
The CPC takes into account both the distance _between_ clusters and the concentration of attitudes _within_ clusters.
That is, this measure takes into account both dynamics of polarization: it increases when the distance between clusters increases or when clusters become more tightly concentrated around their respective centroids.
Intuitively, it is bounded between 0, no polarization, and 1, maximal polarization.

In light of its advantages, this project will employ the CPC as its measure of polarization.
This will involve three tasks.
The first task is to identify the potentially politically relevant social cleavages about which climate-change opinion may be polarized and data on each.
The classic formulation of social cleavages in @Lipset1967 suggests left and right, urban and rural, and religious and secular; differences in attitudes across female and male respondents can be added to this list.
This project will identify the variables tapping these four potentially politically relevant social cleavages within each of the surveys containing questions on climate change attitudes and incorporate this information into the `DCPOtools` R package.
This will allow the automatic collection and processing of climate-change opinion data for each of these groups within each country and year in a dataset.

The second task is to revise and expand the DCPO model to generate CPC estimates of polarization.
This will involve generating estimates for multiple groups within each country-year and then calculating the distance between and concentration within each group.
The flexibility of the Stan programming language will make this fairly straightforward.
The revised model will then be incorporated into the `DCPO` R package.

The third and final task under this heading is to use the data collected in the first task and the model revised in the second task to generate CPC estimates of the extent of polarization in each country-year along each of the four social cleavages: male-female, left-right, urban-rural, and religious-secular.
These estimates will allow informative comparisons of the structure of polarization within single country-years, over time within countries, and across countries.


*Disseminating the results.*
We will achieve broad dissemination through conference presentations, three scholarly publications, open-source software, dataverse, and a user-friendly web interface.
In each of the two years of the grant period, the investigators will present their findings at the annual meetings of the Midwest Political Science Association and other conferences.

Specifically, during the first year, the focus will be collecting more survey data on climate-change opinion and then generating mean estimates.
The first scholarly article will focus on these mean estimates of public opinion on climate change and validating them through both convergent validation and construct validation.
According to @Adcock2001, convergent validation compares a given indicator with another indicator of the same concept, while construct validation assesses whether a given indicator is empirically correlated with other indicators in a way that conforms to theoretical expectations.
The investigators will conduct "internal" tests [@Caughey2019; @Woo2024] comparing climate attitudes to responses to the individual survey items employed to generate the estimates as well as "external" tests on other closely related survey items, such as concern for the environment more generally.
For construct validation, the investigators plan to test the relationship between climate attitude and exposure to disasters [see, e.g., @Sloggy2021].

In the second year, the `DCPOtools` and `DCPO` packages will be updated to measure polarization in climate change attitudes across different subpopulation groups across countries over time.
This work will be presented at the MPSA and form the basis of the second scholarly article.

Meanwhile, the investigators will apply these estimates to study the dynamic relationship between climate change attitudes, polarization, and climate-policy adoption in cross-sectional time-series data.
The third paper examines how public climate change concerns and policy preferences impact climate policy adoption. 
Using our measures of public opinion and polarization, we will analyze the relationship between public opinion and climate policy adoption across countries over time.
We will use data from the Climate Change Laws of the World [@Nachmany2017], which compiles laws and regulations aimed at reducing carbon emissions and promoting clean energy.
The main outcome variable is the number of new climate policies adopted per country-year, with the previous year's cumulative climate policies as a control variable.
This approach tests how current levels of public concern about climate change contribute to the existing level of climate laws and regulations.^[
We will control for GDP per capita (log), oil rent (% of GDP), coal rent (% of GDP), and CO2 emissions per capita using World Development Indicators (WDI).
Political regime effects will be controlled using the liberal democracy variable from the V-Dem Dataset.
To account for the impact of climate-related natural disasters on policy adoption, we will use data from the Emergency Events Database (EM-DAT), which includes global natural disaster data.
For empirical analysis, we will employ a two-way fixed effects model with robust standard errors at both time and entity levels to control for unobserved heterogeneity in panel data.]
Additionally, the PIs will take advantage of conference time for in-person, in-depth project meetings to exchange ideas and set the agenda.

Beyond conference presentations and three scholarly publications, the investigators will disseminate the mean and polarization estimates through the Harvard Dataverse, provide two updated `DCPOtools` and `DCPO` packages, and develop a user-friendly dashboard for access on the web.
Climate scholars can download the estimates directly from the Dataverse for use in downstream analyses.
The updated DCPO packages will enable scholars to measure public opinion of their interests, from data collection and data wrangling to generating estimates.
The user-friendly dashboard will be a valuable tool for the general public to explore temporal trends and compare spatial differences in public climate change attitudes, allowing users to visualize data based on their preferred time period, demographics, country, or region.


### Timeline and Project Implementation
The proposed project will take two years, estimated based on initial efforts in collecting, cleaning, and examining survey data.
During the two-year project, the investigators will expand the coverage of the survey data in terms of country-year and country-year-items, measure public opinion, revise and improve DCPO models to measure polarization, and write three scholarly papers and disseminate our estimates. 
The plan for the project timeline is outlined as follows:

Summer and Fall 2025: Raw data collection.
In the first year, in addition to expand temporal coverage from recently released data, the investigators will focus on expanding the data to include single-country surveys, which as described above are often disseminated only in their original languages, and surveys that are not publicly available.
Due to language and transcription challenges, these single-country surveys usually take longer to identify, collect, and clean.

The project team will write a codebook for item selection, train research assistants to code items, conduct inter-coder reliability tests, and update the codebook to achieve a higher level of intercoder reliability.
This process will involve several rounds of discussions and revisions, potentially extending the timeline.

Spring 2026: Estimate climate change public opinion measures and write up the first scholarly paper on measures and validations.
Once the mean public opinion measures are ready, as described above, the investigators will draft the first paper on these measures and validate them.
The mean opinion data will be presented at the MPSA conference in spring 2026, ensuring feedback from peers.
As the paper moves into the publication process, the investigators will bring the web interface online, making the mean opinion data available for download and user interaction.

Summer 2026: Revise DCPO models and packages for estimating polarization; collect demographic information from survey data for measuring polarization.
During the summer, the project team will collect information on variables tapping the social cleavages and incorporate it into the `DCPOtools` R package.
This information will be essential for generating the estimates of polarization in climate-change opinion.
The investigators will revise the DCPO model to measure climate change opinion within subpopulations and generate the CPC measure of polarization. 

Fall 2026: Estimate climate change polarization, compare polarization across social cleavages, and draft a paper on climate change polarization estimates and validations.
The second paper, focusing on polarization in climate-change opinion, will be written during this time. 

Spring 2027: Finalize data collection for dynamic analysis up to recent years and conduct analysis on the relationship between public opinion, polarization, and policy outputs.
The project team will finalize the collection of other data required for the third paper on dynamics between public opinion and policy and perform the analyses.
The second paper, on polarization, and the third paper, on the dynamics of opinion and policy, will be presented at the MPSA conference this spring.
The polarization measures will be added to the web interface. 

Summer 2027: Finalize the paper about dynamic relationship between climate public opinion and climate policies and submit for publication.

### Broader Impacts
The resulting Climate Change Public Opinion Dataset (CCPOD) will serve as a crucial research infrastructure for researchers, educators, students, policymakers, non-governmental organizations, and news agencies worldwide, fostering both within and cross-national work on climate change, polarization, and broader public opinion.
Through conference presentations, scholarly publications, and a user-friendly web interface, the dissemination of the resulting estimates will enhance the understanding of scholars, policymakers, NGOs, journalists, and the general public about the relationship between public opinion and climate policies, ultimately contributing to more informed and effective climate change action.
In addition, two open-source R packages for automating data collection and measurement are made available so others can analyze similar data.
This aligns with NSF's commitment to making knowledge accessible to policymakers, the public, and researchers.
Moreover, this project will promote teaching by providing CCPOD's web-based graphical interface with user-friendly functionality to facilitate its use for teaching and learning and by employing graduate research assistants, especially members of marginalized groups, who will develop valuable new skills in this important interdisciplinary field.


### Results From Prior NSF Support
Co-PIs Cao and Tai have received no prior NSF support.

PI Solt was PI of NSF Award Number 1533746, "Standardized World Income Inequality Database" (SWIID), in the amount of $228,809.00, which began on August 15, 2015 and was successfully completed on July 31, 2019.

_Intellectual Merit._
Income inequality is an enduring focus of inquiry in the social sciences that has attracted renewed attention from policymakers and the public, but research has been hindered by a choice between data coverage and data comparability.
The Standardized World Income Inequality Database (SWIID) overcomes this tradeoff by using a Bayesian latent-variable model on data drawn from regional collections, national statistical offices, and academic studies anchored by the high-quality but sparse Luxembourg Income Study dataset.
The SWIID currently provides comparable estimates of market- and net-income inequality for 199 countries for as many years as possible from 1960 to the present.
It also includes information on absolute and relative redistribution, creating crucial infrastructure for research on the causes and consequences of income inequality.
The proposed research comprised four principal activities to improve the SWIID project: (1) acquiring and cleaning data to expand its coverage, (2) assessing and improving the techniques used to ensure its estimates are comparable, (3) expanding documentation to help researchers use income-inequality data in ways appropriate to their research questions, and (4) improving the web-based system for disseminating the SWIID to researchers, educators, and policymakers worldwide.

Economists, political scientists, sociologists, and other social scientists have long sought to explain why incomes are relatively equal in some countries and times and much larger disparities between rich and poor are found in others.
The effects of income inequality on other forms of social inequality, such as health disparities, and on other phenomena ranging from political violence to economic growth to democratic transitions are similarly vital questions.
The reliability of the results of these investigations, and any policy interventions they suggest, depend crucially on the quality of the income-inequality data they employ.
The expansion, improvement, and support of the SWIID database was (and remains) central to the promotion of scientific progress on these topics and matched NSF priorities outlined in the NSF Strategic Plan 2011-2016, most especially in transforming frontiers of knowledge by building research infrastructure and data access, facilitating international engagement in science, and emphasizing interdisciplinary research.

_Broader Impacts._
The project resulted in (1) the publication of @Solt2020, which is listed by the Web of Science _Essential Science Indicators_ as a Highly Cited Paper, among the top 1% most cited articles in the social sciences (excluding economics) for its year of publication; (2) biannual updates to the SWIID on the Harvard Dataverse each year since 2017 that collectively have been downloaded more than 150,000 times; and (3) the SWIID website, which provides a user-friendly interface to the dataset and receives in excess of 100 visitors daily.
The SWIID has been used by thousands of researchers around the world who are working in academia, governments, non-governmental organizations, international organizations, and news agencies; the broad dissemination of expanded and improved versions of the SWIID therefore comports with NSF's longstanding commitment to making knowledge accessible to policymakers and the public as well as to researchers.
Moreover, this project promoted teaching by improving the SWIID's web-based graphical interface to facilitate its use for teaching and learning; developing online training modules on the use of cross-national income-inequality data over time; and employing a graduate research assistant who is a member of an underrepresented group, finished her Ph.D. in 2021, and is now a tenure-track assistant professor, helping contribute to the development of a diverse, globally competitive STEM workforce.





\newpage

## References

\indent
\setlength{\parindent}{-.5in}
\setlength{\leftskip}{0.5in}








